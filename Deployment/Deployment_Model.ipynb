{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv('../../Data/iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.drop('species', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = iris['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelBinarizer()\n",
    "y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train = scaler.transform(X_train)\n",
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4, activation='relu', input_shape=[4,]))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/300\n",
      "120/120 [==============================] - 0s 3ms/sample - loss: 1.0872 - accuracy: 0.3167 - val_loss: 1.0628 - val_accuracy: 0.4000\n",
      "Epoch 2/300\n",
      "120/120 [==============================] - 0s 93us/sample - loss: 1.0809 - accuracy: 0.3167 - val_loss: 1.0591 - val_accuracy: 0.4000\n",
      "Epoch 3/300\n",
      "120/120 [==============================] - 0s 287us/sample - loss: 1.0749 - accuracy: 0.3167 - val_loss: 1.0557 - val_accuracy: 0.4000\n",
      "Epoch 4/300\n",
      "120/120 [==============================] - 0s 135us/sample - loss: 1.0695 - accuracy: 0.3167 - val_loss: 1.0523 - val_accuracy: 0.4000\n",
      "Epoch 5/300\n",
      "120/120 [==============================] - 0s 184us/sample - loss: 1.0638 - accuracy: 0.3167 - val_loss: 1.0490 - val_accuracy: 0.4000\n",
      "Epoch 6/300\n",
      "120/120 [==============================] - 0s 201us/sample - loss: 1.0582 - accuracy: 0.3167 - val_loss: 1.0457 - val_accuracy: 0.4000\n",
      "Epoch 7/300\n",
      "120/120 [==============================] - 0s 163us/sample - loss: 1.0531 - accuracy: 0.3167 - val_loss: 1.0426 - val_accuracy: 0.4000\n",
      "Epoch 8/300\n",
      "120/120 [==============================] - 0s 99us/sample - loss: 1.0483 - accuracy: 0.3167 - val_loss: 1.0396 - val_accuracy: 0.4000\n",
      "Epoch 9/300\n",
      "120/120 [==============================] - 0s 138us/sample - loss: 1.0433 - accuracy: 0.3167 - val_loss: 1.0367 - val_accuracy: 0.4000\n",
      "Epoch 10/300\n",
      "120/120 [==============================] - 0s 128us/sample - loss: 1.0385 - accuracy: 0.3167 - val_loss: 1.0338 - val_accuracy: 0.4000\n",
      "Epoch 11/300\n",
      "120/120 [==============================] - 0s 126us/sample - loss: 1.0337 - accuracy: 0.3167 - val_loss: 1.0309 - val_accuracy: 0.3667\n",
      "Epoch 12/300\n",
      "120/120 [==============================] - 0s 124us/sample - loss: 1.0293 - accuracy: 0.3083 - val_loss: 1.0280 - val_accuracy: 0.3667\n",
      "Epoch 13/300\n",
      "120/120 [==============================] - 0s 143us/sample - loss: 1.0252 - accuracy: 0.3167 - val_loss: 1.0253 - val_accuracy: 0.3333\n",
      "Epoch 14/300\n",
      "120/120 [==============================] - 0s 137us/sample - loss: 1.0204 - accuracy: 0.3000 - val_loss: 1.0225 - val_accuracy: 0.3000\n",
      "Epoch 15/300\n",
      "120/120 [==============================] - 0s 127us/sample - loss: 1.0162 - accuracy: 0.2833 - val_loss: 1.0197 - val_accuracy: 0.2667\n",
      "Epoch 16/300\n",
      "120/120 [==============================] - 0s 114us/sample - loss: 1.0119 - accuracy: 0.2750 - val_loss: 1.0169 - val_accuracy: 0.2333\n",
      "Epoch 17/300\n",
      "120/120 [==============================] - 0s 156us/sample - loss: 1.0077 - accuracy: 0.2667 - val_loss: 1.0141 - val_accuracy: 0.2000\n",
      "Epoch 18/300\n",
      "120/120 [==============================] - 0s 169us/sample - loss: 1.0034 - accuracy: 0.2500 - val_loss: 1.0112 - val_accuracy: 0.1667\n",
      "Epoch 19/300\n",
      "120/120 [==============================] - 0s 116us/sample - loss: 0.9992 - accuracy: 0.2333 - val_loss: 1.0084 - val_accuracy: 0.1667\n",
      "Epoch 20/300\n",
      "120/120 [==============================] - 0s 147us/sample - loss: 0.9949 - accuracy: 0.2167 - val_loss: 1.0054 - val_accuracy: 0.1667\n",
      "Epoch 21/300\n",
      "120/120 [==============================] - 0s 143us/sample - loss: 0.9907 - accuracy: 0.2167 - val_loss: 1.0026 - val_accuracy: 0.1667\n",
      "Epoch 22/300\n",
      "120/120 [==============================] - 0s 156us/sample - loss: 0.9867 - accuracy: 0.2083 - val_loss: 0.9997 - val_accuracy: 0.1667\n",
      "Epoch 23/300\n",
      "120/120 [==============================] - 0s 144us/sample - loss: 0.9828 - accuracy: 0.1917 - val_loss: 0.9971 - val_accuracy: 0.2000\n",
      "Epoch 24/300\n",
      "120/120 [==============================] - 0s 131us/sample - loss: 0.9791 - accuracy: 0.2000 - val_loss: 0.9948 - val_accuracy: 0.2333\n",
      "Epoch 25/300\n",
      "120/120 [==============================] - 0s 123us/sample - loss: 0.9750 - accuracy: 0.2250 - val_loss: 0.9921 - val_accuracy: 0.2667\n",
      "Epoch 26/300\n",
      "120/120 [==============================] - 0s 155us/sample - loss: 0.9712 - accuracy: 0.2333 - val_loss: 0.9893 - val_accuracy: 0.2667\n",
      "Epoch 27/300\n",
      "120/120 [==============================] - 0s 143us/sample - loss: 0.9673 - accuracy: 0.2500 - val_loss: 0.9864 - val_accuracy: 0.2667\n",
      "Epoch 28/300\n",
      "120/120 [==============================] - 0s 130us/sample - loss: 0.9636 - accuracy: 0.2667 - val_loss: 0.9835 - val_accuracy: 0.2667\n",
      "Epoch 29/300\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.9600 - accuracy: 0.2917 - val_loss: 0.9808 - val_accuracy: 0.2667\n",
      "Epoch 30/300\n",
      "120/120 [==============================] - 0s 155us/sample - loss: 0.9564 - accuracy: 0.3000 - val_loss: 0.9782 - val_accuracy: 0.2667\n",
      "Epoch 31/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.9532 - accuracy: 0.3250 - val_loss: 0.9760 - val_accuracy: 0.2667\n",
      "Epoch 32/300\n",
      "120/120 [==============================] - 0s 159us/sample - loss: 0.9496 - accuracy: 0.3250 - val_loss: 0.9736 - val_accuracy: 0.3000\n",
      "Epoch 33/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.9464 - accuracy: 0.3333 - val_loss: 0.9713 - val_accuracy: 0.2667\n",
      "Epoch 34/300\n",
      "120/120 [==============================] - 0s 140us/sample - loss: 0.9431 - accuracy: 0.3417 - val_loss: 0.9690 - val_accuracy: 0.3000\n",
      "Epoch 35/300\n",
      "120/120 [==============================] - 0s 204us/sample - loss: 0.9398 - accuracy: 0.3500 - val_loss: 0.9668 - val_accuracy: 0.3000\n",
      "Epoch 36/300\n",
      "120/120 [==============================] - 0s 209us/sample - loss: 0.9367 - accuracy: 0.3500 - val_loss: 0.9645 - val_accuracy: 0.3000\n",
      "Epoch 37/300\n",
      "120/120 [==============================] - 0s 205us/sample - loss: 0.9337 - accuracy: 0.3583 - val_loss: 0.9623 - val_accuracy: 0.3333\n",
      "Epoch 38/300\n",
      "120/120 [==============================] - 0s 152us/sample - loss: 0.9305 - accuracy: 0.3667 - val_loss: 0.9600 - val_accuracy: 0.3000\n",
      "Epoch 39/300\n",
      "120/120 [==============================] - 0s 134us/sample - loss: 0.9277 - accuracy: 0.3750 - val_loss: 0.9578 - val_accuracy: 0.3333\n",
      "Epoch 40/300\n",
      "120/120 [==============================] - 0s 126us/sample - loss: 0.9248 - accuracy: 0.3750 - val_loss: 0.9557 - val_accuracy: 0.3667\n",
      "Epoch 41/300\n",
      "120/120 [==============================] - 0s 165us/sample - loss: 0.9218 - accuracy: 0.3833 - val_loss: 0.9535 - val_accuracy: 0.4000\n",
      "Epoch 42/300\n",
      "120/120 [==============================] - 0s 135us/sample - loss: 0.9187 - accuracy: 0.4000 - val_loss: 0.9510 - val_accuracy: 0.4667\n",
      "Epoch 43/300\n",
      "120/120 [==============================] - 0s 130us/sample - loss: 0.9159 - accuracy: 0.4500 - val_loss: 0.9487 - val_accuracy: 0.4667\n",
      "Epoch 44/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.9129 - accuracy: 0.4917 - val_loss: 0.9463 - val_accuracy: 0.4667\n",
      "Epoch 45/300\n",
      "120/120 [==============================] - 0s 155us/sample - loss: 0.9101 - accuracy: 0.5500 - val_loss: 0.9440 - val_accuracy: 0.4667\n",
      "Epoch 46/300\n",
      "120/120 [==============================] - 0s 156us/sample - loss: 0.9073 - accuracy: 0.5667 - val_loss: 0.9417 - val_accuracy: 0.4667\n",
      "Epoch 47/300\n",
      "120/120 [==============================] - 0s 157us/sample - loss: 0.9044 - accuracy: 0.5667 - val_loss: 0.9393 - val_accuracy: 0.5000\n",
      "Epoch 48/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.9016 - accuracy: 0.5833 - val_loss: 0.9368 - val_accuracy: 0.5000\n",
      "Epoch 49/300\n",
      "120/120 [==============================] - 0s 131us/sample - loss: 0.8990 - accuracy: 0.6167 - val_loss: 0.9349 - val_accuracy: 0.5000\n",
      "Epoch 50/300\n",
      "120/120 [==============================] - 0s 127us/sample - loss: 0.8960 - accuracy: 0.6250 - val_loss: 0.9324 - val_accuracy: 0.5333\n",
      "Epoch 51/300\n",
      "120/120 [==============================] - 0s 124us/sample - loss: 0.8932 - accuracy: 0.6250 - val_loss: 0.9300 - val_accuracy: 0.5667\n",
      "Epoch 52/300\n",
      "120/120 [==============================] - 0s 107us/sample - loss: 0.8904 - accuracy: 0.6417 - val_loss: 0.9279 - val_accuracy: 0.6333\n",
      "Epoch 53/300\n",
      "120/120 [==============================] - 0s 103us/sample - loss: 0.8876 - accuracy: 0.6583 - val_loss: 0.9257 - val_accuracy: 0.6333\n",
      "Epoch 54/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.8848 - accuracy: 0.6583 - val_loss: 0.9235 - val_accuracy: 0.6667\n",
      "Epoch 55/300\n",
      "120/120 [==============================] - 0s 123us/sample - loss: 0.8820 - accuracy: 0.6667 - val_loss: 0.9211 - val_accuracy: 0.6333\n",
      "Epoch 56/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 121us/sample - loss: 0.8794 - accuracy: 0.6667 - val_loss: 0.9190 - val_accuracy: 0.6000\n",
      "Epoch 57/300\n",
      "120/120 [==============================] - 0s 111us/sample - loss: 0.8765 - accuracy: 0.6750 - val_loss: 0.9168 - val_accuracy: 0.6000\n",
      "Epoch 58/300\n",
      "120/120 [==============================] - 0s 137us/sample - loss: 0.8739 - accuracy: 0.6750 - val_loss: 0.9146 - val_accuracy: 0.5667\n",
      "Epoch 59/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.8710 - accuracy: 0.6833 - val_loss: 0.9120 - val_accuracy: 0.5667\n",
      "Epoch 60/300\n",
      "120/120 [==============================] - 0s 102us/sample - loss: 0.8683 - accuracy: 0.6833 - val_loss: 0.9098 - val_accuracy: 0.5667\n",
      "Epoch 61/300\n",
      "120/120 [==============================] - 0s 110us/sample - loss: 0.8655 - accuracy: 0.6833 - val_loss: 0.9074 - val_accuracy: 0.5667\n",
      "Epoch 62/300\n",
      "120/120 [==============================] - 0s 101us/sample - loss: 0.8629 - accuracy: 0.6833 - val_loss: 0.9052 - val_accuracy: 0.5667\n",
      "Epoch 63/300\n",
      "120/120 [==============================] - 0s 110us/sample - loss: 0.8601 - accuracy: 0.6750 - val_loss: 0.9029 - val_accuracy: 0.5667\n",
      "Epoch 64/300\n",
      "120/120 [==============================] - 0s 106us/sample - loss: 0.8576 - accuracy: 0.6750 - val_loss: 0.9007 - val_accuracy: 0.5667\n",
      "Epoch 65/300\n",
      "120/120 [==============================] - 0s 107us/sample - loss: 0.8547 - accuracy: 0.6750 - val_loss: 0.8982 - val_accuracy: 0.5667\n",
      "Epoch 66/300\n",
      "120/120 [==============================] - 0s 110us/sample - loss: 0.8521 - accuracy: 0.6833 - val_loss: 0.8958 - val_accuracy: 0.5667\n",
      "Epoch 67/300\n",
      "120/120 [==============================] - 0s 94us/sample - loss: 0.8493 - accuracy: 0.6833 - val_loss: 0.8935 - val_accuracy: 0.5667\n",
      "Epoch 68/300\n",
      "120/120 [==============================] - 0s 95us/sample - loss: 0.8468 - accuracy: 0.6917 - val_loss: 0.8914 - val_accuracy: 0.5667\n",
      "Epoch 69/300\n",
      "120/120 [==============================] - 0s 96us/sample - loss: 0.8440 - accuracy: 0.6917 - val_loss: 0.8889 - val_accuracy: 0.5667\n",
      "Epoch 70/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.8414 - accuracy: 0.6917 - val_loss: 0.8866 - val_accuracy: 0.6000\n",
      "Epoch 71/300\n",
      "120/120 [==============================] - 0s 113us/sample - loss: 0.8387 - accuracy: 0.6917 - val_loss: 0.8842 - val_accuracy: 0.6000\n",
      "Epoch 72/300\n",
      "120/120 [==============================] - 0s 128us/sample - loss: 0.8361 - accuracy: 0.6917 - val_loss: 0.8818 - val_accuracy: 0.6333\n",
      "Epoch 73/300\n",
      "120/120 [==============================] - 0s 114us/sample - loss: 0.8335 - accuracy: 0.6917 - val_loss: 0.8795 - val_accuracy: 0.6333\n",
      "Epoch 74/300\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.8309 - accuracy: 0.6917 - val_loss: 0.8772 - val_accuracy: 0.6333\n",
      "Epoch 75/300\n",
      "120/120 [==============================] - 0s 122us/sample - loss: 0.8282 - accuracy: 0.6917 - val_loss: 0.8747 - val_accuracy: 0.6333\n",
      "Epoch 76/300\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.8257 - accuracy: 0.7000 - val_loss: 0.8721 - val_accuracy: 0.6333\n",
      "Epoch 77/300\n",
      "120/120 [==============================] - 0s 119us/sample - loss: 0.8231 - accuracy: 0.6917 - val_loss: 0.8699 - val_accuracy: 0.6333\n",
      "Epoch 78/300\n",
      "120/120 [==============================] - 0s 116us/sample - loss: 0.8204 - accuracy: 0.6917 - val_loss: 0.8676 - val_accuracy: 0.6333\n",
      "Epoch 79/300\n",
      "120/120 [==============================] - 0s 110us/sample - loss: 0.8178 - accuracy: 0.7000 - val_loss: 0.8652 - val_accuracy: 0.6333\n",
      "Epoch 80/300\n",
      "120/120 [==============================] - 0s 103us/sample - loss: 0.8154 - accuracy: 0.7000 - val_loss: 0.8628 - val_accuracy: 0.6333\n",
      "Epoch 81/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.8128 - accuracy: 0.7000 - val_loss: 0.8605 - val_accuracy: 0.6333\n",
      "Epoch 82/300\n",
      "120/120 [==============================] - 0s 104us/sample - loss: 0.8102 - accuracy: 0.7000 - val_loss: 0.8583 - val_accuracy: 0.6333\n",
      "Epoch 83/300\n",
      "120/120 [==============================] - 0s 98us/sample - loss: 0.8077 - accuracy: 0.7000 - val_loss: 0.8559 - val_accuracy: 0.6333\n",
      "Epoch 84/300\n",
      "120/120 [==============================] - 0s 122us/sample - loss: 0.8052 - accuracy: 0.7000 - val_loss: 0.8532 - val_accuracy: 0.6333\n",
      "Epoch 85/300\n",
      "120/120 [==============================] - 0s 124us/sample - loss: 0.8026 - accuracy: 0.7000 - val_loss: 0.8509 - val_accuracy: 0.6333\n",
      "Epoch 86/300\n",
      "120/120 [==============================] - 0s 95us/sample - loss: 0.8001 - accuracy: 0.7000 - val_loss: 0.8486 - val_accuracy: 0.6333\n",
      "Epoch 87/300\n",
      "120/120 [==============================] - 0s 103us/sample - loss: 0.7976 - accuracy: 0.7000 - val_loss: 0.8464 - val_accuracy: 0.6333\n",
      "Epoch 88/300\n",
      "120/120 [==============================] - 0s 118us/sample - loss: 0.7954 - accuracy: 0.7000 - val_loss: 0.8446 - val_accuracy: 0.6333\n",
      "Epoch 89/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.7926 - accuracy: 0.7000 - val_loss: 0.8423 - val_accuracy: 0.6333\n",
      "Epoch 90/300\n",
      "120/120 [==============================] - 0s 128us/sample - loss: 0.7902 - accuracy: 0.7000 - val_loss: 0.8399 - val_accuracy: 0.6333\n",
      "Epoch 91/300\n",
      "120/120 [==============================] - 0s 103us/sample - loss: 0.7877 - accuracy: 0.7000 - val_loss: 0.8376 - val_accuracy: 0.6333\n",
      "Epoch 92/300\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.7853 - accuracy: 0.7000 - val_loss: 0.8357 - val_accuracy: 0.6333\n",
      "Epoch 93/300\n",
      "120/120 [==============================] - 0s 120us/sample - loss: 0.7829 - accuracy: 0.7000 - val_loss: 0.8337 - val_accuracy: 0.6333\n",
      "Epoch 94/300\n",
      "120/120 [==============================] - 0s 116us/sample - loss: 0.7804 - accuracy: 0.7000 - val_loss: 0.8314 - val_accuracy: 0.6333\n",
      "Epoch 95/300\n",
      "120/120 [==============================] - 0s 111us/sample - loss: 0.7779 - accuracy: 0.7000 - val_loss: 0.8292 - val_accuracy: 0.6333\n",
      "Epoch 96/300\n",
      "120/120 [==============================] - 0s 97us/sample - loss: 0.7757 - accuracy: 0.7000 - val_loss: 0.8268 - val_accuracy: 0.6333\n",
      "Epoch 97/300\n",
      "120/120 [==============================] - 0s 114us/sample - loss: 0.7733 - accuracy: 0.7000 - val_loss: 0.8249 - val_accuracy: 0.6333\n",
      "Epoch 98/300\n",
      "120/120 [==============================] - 0s 106us/sample - loss: 0.7708 - accuracy: 0.7000 - val_loss: 0.8228 - val_accuracy: 0.6333\n",
      "Epoch 99/300\n",
      "120/120 [==============================] - 0s 97us/sample - loss: 0.7684 - accuracy: 0.7000 - val_loss: 0.8206 - val_accuracy: 0.6333\n",
      "Epoch 100/300\n",
      "120/120 [==============================] - 0s 128us/sample - loss: 0.7662 - accuracy: 0.7000 - val_loss: 0.8185 - val_accuracy: 0.6333\n",
      "Epoch 101/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.7638 - accuracy: 0.7000 - val_loss: 0.8163 - val_accuracy: 0.6333\n",
      "Epoch 102/300\n",
      "120/120 [==============================] - 0s 118us/sample - loss: 0.7614 - accuracy: 0.7000 - val_loss: 0.8143 - val_accuracy: 0.6333\n",
      "Epoch 103/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.7591 - accuracy: 0.7000 - val_loss: 0.8121 - val_accuracy: 0.6333\n",
      "Epoch 104/300\n",
      "120/120 [==============================] - 0s 107us/sample - loss: 0.7568 - accuracy: 0.7083 - val_loss: 0.8099 - val_accuracy: 0.6333\n",
      "Epoch 105/300\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.7545 - accuracy: 0.7083 - val_loss: 0.8079 - val_accuracy: 0.6333\n",
      "Epoch 106/300\n",
      "120/120 [==============================] - 0s 116us/sample - loss: 0.7522 - accuracy: 0.7083 - val_loss: 0.8057 - val_accuracy: 0.6333\n",
      "Epoch 107/300\n",
      "120/120 [==============================] - 0s 101us/sample - loss: 0.7500 - accuracy: 0.7083 - val_loss: 0.8036 - val_accuracy: 0.6333\n",
      "Epoch 108/300\n",
      "120/120 [==============================] - 0s 104us/sample - loss: 0.7477 - accuracy: 0.7083 - val_loss: 0.8014 - val_accuracy: 0.6333\n",
      "Epoch 109/300\n",
      "120/120 [==============================] - 0s 135us/sample - loss: 0.7454 - accuracy: 0.7083 - val_loss: 0.7991 - val_accuracy: 0.6333\n",
      "Epoch 110/300\n",
      "120/120 [==============================] - 0s 128us/sample - loss: 0.7432 - accuracy: 0.7083 - val_loss: 0.7968 - val_accuracy: 0.6333\n",
      "Epoch 111/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 119us/sample - loss: 0.7412 - accuracy: 0.7083 - val_loss: 0.7952 - val_accuracy: 0.6333\n",
      "Epoch 112/300\n",
      "120/120 [==============================] - 0s 121us/sample - loss: 0.7387 - accuracy: 0.7083 - val_loss: 0.7930 - val_accuracy: 0.6333\n",
      "Epoch 113/300\n",
      "120/120 [==============================] - 0s 101us/sample - loss: 0.7366 - accuracy: 0.7083 - val_loss: 0.7906 - val_accuracy: 0.6333\n",
      "Epoch 114/300\n",
      "120/120 [==============================] - 0s 99us/sample - loss: 0.7343 - accuracy: 0.7083 - val_loss: 0.7887 - val_accuracy: 0.6333\n",
      "Epoch 115/300\n",
      "120/120 [==============================] - 0s 90us/sample - loss: 0.7321 - accuracy: 0.7083 - val_loss: 0.7866 - val_accuracy: 0.6333\n",
      "Epoch 116/300\n",
      "120/120 [==============================] - 0s 112us/sample - loss: 0.7299 - accuracy: 0.7083 - val_loss: 0.7845 - val_accuracy: 0.6333\n",
      "Epoch 117/300\n",
      "120/120 [==============================] - 0s 116us/sample - loss: 0.7277 - accuracy: 0.7083 - val_loss: 0.7823 - val_accuracy: 0.6333\n",
      "Epoch 118/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.7256 - accuracy: 0.7083 - val_loss: 0.7804 - val_accuracy: 0.6333\n",
      "Epoch 119/300\n",
      "120/120 [==============================] - 0s 90us/sample - loss: 0.7233 - accuracy: 0.7083 - val_loss: 0.7782 - val_accuracy: 0.6333\n",
      "Epoch 120/300\n",
      "120/120 [==============================] - 0s 89us/sample - loss: 0.7214 - accuracy: 0.7083 - val_loss: 0.7758 - val_accuracy: 0.6333\n",
      "Epoch 121/300\n",
      "120/120 [==============================] - 0s 104us/sample - loss: 0.7190 - accuracy: 0.7083 - val_loss: 0.7738 - val_accuracy: 0.6333\n",
      "Epoch 122/300\n",
      "120/120 [==============================] - 0s 87us/sample - loss: 0.7169 - accuracy: 0.7083 - val_loss: 0.7718 - val_accuracy: 0.6333\n",
      "Epoch 123/300\n",
      "120/120 [==============================] - 0s 113us/sample - loss: 0.7148 - accuracy: 0.7083 - val_loss: 0.7700 - val_accuracy: 0.6333\n",
      "Epoch 124/300\n",
      "120/120 [==============================] - 0s 96us/sample - loss: 0.7128 - accuracy: 0.7083 - val_loss: 0.7679 - val_accuracy: 0.6333\n",
      "Epoch 125/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.7106 - accuracy: 0.7083 - val_loss: 0.7660 - val_accuracy: 0.6333\n",
      "Epoch 126/300\n",
      "120/120 [==============================] - 0s 111us/sample - loss: 0.7086 - accuracy: 0.7083 - val_loss: 0.7642 - val_accuracy: 0.6333\n",
      "Epoch 127/300\n",
      "120/120 [==============================] - 0s 96us/sample - loss: 0.7065 - accuracy: 0.7083 - val_loss: 0.7624 - val_accuracy: 0.6333\n",
      "Epoch 128/300\n",
      "120/120 [==============================] - 0s 90us/sample - loss: 0.7045 - accuracy: 0.7083 - val_loss: 0.7600 - val_accuracy: 0.6333\n",
      "Epoch 129/300\n",
      "120/120 [==============================] - 0s 102us/sample - loss: 0.7024 - accuracy: 0.7167 - val_loss: 0.7579 - val_accuracy: 0.6333\n",
      "Epoch 130/300\n",
      "120/120 [==============================] - 0s 114us/sample - loss: 0.7003 - accuracy: 0.7167 - val_loss: 0.7558 - val_accuracy: 0.6333\n",
      "Epoch 131/300\n",
      "120/120 [==============================] - 0s 107us/sample - loss: 0.6982 - accuracy: 0.7167 - val_loss: 0.7539 - val_accuracy: 0.6333\n",
      "Epoch 132/300\n",
      "120/120 [==============================] - 0s 81us/sample - loss: 0.6962 - accuracy: 0.7167 - val_loss: 0.7522 - val_accuracy: 0.6333\n",
      "Epoch 133/300\n",
      "120/120 [==============================] - 0s 104us/sample - loss: 0.6942 - accuracy: 0.7167 - val_loss: 0.7504 - val_accuracy: 0.6333\n",
      "Epoch 134/300\n",
      "120/120 [==============================] - 0s 111us/sample - loss: 0.6924 - accuracy: 0.7167 - val_loss: 0.7488 - val_accuracy: 0.6333\n",
      "Epoch 135/300\n",
      "120/120 [==============================] - 0s 102us/sample - loss: 0.6902 - accuracy: 0.7167 - val_loss: 0.7466 - val_accuracy: 0.6333\n",
      "Epoch 136/300\n",
      "120/120 [==============================] - 0s 86us/sample - loss: 0.6883 - accuracy: 0.7167 - val_loss: 0.7445 - val_accuracy: 0.6333\n",
      "Epoch 137/300\n",
      "120/120 [==============================] - 0s 98us/sample - loss: 0.6863 - accuracy: 0.7167 - val_loss: 0.7426 - val_accuracy: 0.6333\n",
      "Epoch 138/300\n",
      "120/120 [==============================] - 0s 113us/sample - loss: 0.6843 - accuracy: 0.7167 - val_loss: 0.7406 - val_accuracy: 0.6333\n",
      "Epoch 139/300\n",
      "120/120 [==============================] - 0s 116us/sample - loss: 0.6823 - accuracy: 0.7167 - val_loss: 0.7387 - val_accuracy: 0.6333\n",
      "Epoch 140/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.6805 - accuracy: 0.7167 - val_loss: 0.7365 - val_accuracy: 0.7000\n",
      "Epoch 141/300\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.6786 - accuracy: 0.7167 - val_loss: 0.7346 - val_accuracy: 0.7000\n",
      "Epoch 142/300\n",
      "120/120 [==============================] - 0s 93us/sample - loss: 0.6766 - accuracy: 0.7167 - val_loss: 0.7330 - val_accuracy: 0.7000\n",
      "Epoch 143/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.6746 - accuracy: 0.7167 - val_loss: 0.7313 - val_accuracy: 0.7000\n",
      "Epoch 144/300\n",
      "120/120 [==============================] - 0s 107us/sample - loss: 0.6727 - accuracy: 0.7167 - val_loss: 0.7295 - val_accuracy: 0.7000\n",
      "Epoch 145/300\n",
      "120/120 [==============================] - 0s 88us/sample - loss: 0.6708 - accuracy: 0.7167 - val_loss: 0.7279 - val_accuracy: 0.7000\n",
      "Epoch 146/300\n",
      "120/120 [==============================] - 0s 96us/sample - loss: 0.6689 - accuracy: 0.7167 - val_loss: 0.7262 - val_accuracy: 0.7000\n",
      "Epoch 147/300\n",
      "120/120 [==============================] - 0s 110us/sample - loss: 0.6671 - accuracy: 0.7167 - val_loss: 0.7246 - val_accuracy: 0.6667\n",
      "Epoch 148/300\n",
      "120/120 [==============================] - 0s 115us/sample - loss: 0.6652 - accuracy: 0.7167 - val_loss: 0.7228 - val_accuracy: 0.6667\n",
      "Epoch 149/300\n",
      "120/120 [==============================] - 0s 107us/sample - loss: 0.6635 - accuracy: 0.7167 - val_loss: 0.7208 - val_accuracy: 0.7000\n",
      "Epoch 150/300\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 0.6615 - accuracy: 0.7167 - val_loss: 0.7193 - val_accuracy: 0.7000\n",
      "Epoch 151/300\n",
      "120/120 [==============================] - 0s 104us/sample - loss: 0.6596 - accuracy: 0.7167 - val_loss: 0.7176 - val_accuracy: 0.7000\n",
      "Epoch 152/300\n",
      "120/120 [==============================] - 0s 113us/sample - loss: 0.6578 - accuracy: 0.7167 - val_loss: 0.7157 - val_accuracy: 0.7000\n",
      "Epoch 153/300\n",
      "120/120 [==============================] - 0s 129us/sample - loss: 0.6560 - accuracy: 0.7250 - val_loss: 0.7139 - val_accuracy: 0.7000\n",
      "Epoch 154/300\n",
      "120/120 [==============================] - 0s 124us/sample - loss: 0.6541 - accuracy: 0.7250 - val_loss: 0.7120 - val_accuracy: 0.7000\n",
      "Epoch 155/300\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.6523 - accuracy: 0.7250 - val_loss: 0.7104 - val_accuracy: 0.7000\n",
      "Epoch 156/300\n",
      "120/120 [==============================] - 0s 82us/sample - loss: 0.6506 - accuracy: 0.7250 - val_loss: 0.7088 - val_accuracy: 0.7000\n",
      "Epoch 157/300\n",
      "120/120 [==============================] - 0s 110us/sample - loss: 0.6488 - accuracy: 0.7250 - val_loss: 0.7071 - val_accuracy: 0.7000\n",
      "Epoch 158/300\n",
      "120/120 [==============================] - 0s 111us/sample - loss: 0.6470 - accuracy: 0.7250 - val_loss: 0.7052 - val_accuracy: 0.7000\n",
      "Epoch 159/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.6453 - accuracy: 0.7250 - val_loss: 0.7031 - val_accuracy: 0.7000\n",
      "Epoch 160/300\n",
      "120/120 [==============================] - 0s 110us/sample - loss: 0.6435 - accuracy: 0.7250 - val_loss: 0.7009 - val_accuracy: 0.7000\n",
      "Epoch 161/300\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.6417 - accuracy: 0.7250 - val_loss: 0.6992 - val_accuracy: 0.7000\n",
      "Epoch 162/300\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 0.6400 - accuracy: 0.7250 - val_loss: 0.6974 - val_accuracy: 0.7000\n",
      "Epoch 163/300\n",
      "120/120 [==============================] - 0s 105us/sample - loss: 0.6383 - accuracy: 0.7250 - val_loss: 0.6958 - val_accuracy: 0.7000\n",
      "Epoch 164/300\n",
      "120/120 [==============================] - 0s 118us/sample - loss: 0.6366 - accuracy: 0.7250 - val_loss: 0.6939 - val_accuracy: 0.7000\n",
      "Epoch 165/300\n",
      "120/120 [==============================] - 0s 114us/sample - loss: 0.6348 - accuracy: 0.7250 - val_loss: 0.6924 - val_accuracy: 0.7000\n",
      "Epoch 166/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 123us/sample - loss: 0.6330 - accuracy: 0.7250 - val_loss: 0.6908 - val_accuracy: 0.7000\n",
      "Epoch 167/300\n",
      "120/120 [==============================] - 0s 95us/sample - loss: 0.6314 - accuracy: 0.7250 - val_loss: 0.6894 - val_accuracy: 0.7000\n",
      "Epoch 168/300\n",
      "120/120 [==============================] - 0s 94us/sample - loss: 0.6298 - accuracy: 0.7250 - val_loss: 0.6879 - val_accuracy: 0.7000\n",
      "Epoch 169/300\n",
      "120/120 [==============================] - 0s 101us/sample - loss: 0.6281 - accuracy: 0.7250 - val_loss: 0.6863 - val_accuracy: 0.7000\n",
      "Epoch 170/300\n",
      "120/120 [==============================] - 0s 119us/sample - loss: 0.6264 - accuracy: 0.7250 - val_loss: 0.6849 - val_accuracy: 0.7000\n",
      "Epoch 171/300\n",
      "120/120 [==============================] - 0s 118us/sample - loss: 0.6248 - accuracy: 0.7250 - val_loss: 0.6834 - val_accuracy: 0.7000\n",
      "Epoch 172/300\n",
      "120/120 [==============================] - 0s 141us/sample - loss: 0.6231 - accuracy: 0.7250 - val_loss: 0.6818 - val_accuracy: 0.7000\n",
      "Epoch 173/300\n",
      "120/120 [==============================] - 0s 159us/sample - loss: 0.6215 - accuracy: 0.7250 - val_loss: 0.6803 - val_accuracy: 0.7000\n",
      "Epoch 174/300\n",
      "120/120 [==============================] - 0s 143us/sample - loss: 0.6199 - accuracy: 0.7250 - val_loss: 0.6786 - val_accuracy: 0.7000\n",
      "Epoch 175/300\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.6183 - accuracy: 0.7250 - val_loss: 0.6770 - val_accuracy: 0.7000\n",
      "Epoch 176/300\n",
      "120/120 [==============================] - 0s 121us/sample - loss: 0.6166 - accuracy: 0.7250 - val_loss: 0.6753 - val_accuracy: 0.7000\n",
      "Epoch 177/300\n",
      "120/120 [==============================] - 0s 131us/sample - loss: 0.6150 - accuracy: 0.7250 - val_loss: 0.6734 - val_accuracy: 0.7000\n",
      "Epoch 178/300\n",
      "120/120 [==============================] - 0s 179us/sample - loss: 0.6134 - accuracy: 0.7250 - val_loss: 0.6717 - val_accuracy: 0.7000\n",
      "Epoch 179/300\n",
      "120/120 [==============================] - 0s 128us/sample - loss: 0.6118 - accuracy: 0.7250 - val_loss: 0.6701 - val_accuracy: 0.7000\n",
      "Epoch 180/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.6103 - accuracy: 0.7250 - val_loss: 0.6685 - val_accuracy: 0.7000\n",
      "Epoch 181/300\n",
      "120/120 [==============================] - 0s 160us/sample - loss: 0.6088 - accuracy: 0.7333 - val_loss: 0.6666 - val_accuracy: 0.7000\n",
      "Epoch 182/300\n",
      "120/120 [==============================] - 0s 122us/sample - loss: 0.6072 - accuracy: 0.7333 - val_loss: 0.6651 - val_accuracy: 0.7000\n",
      "Epoch 183/300\n",
      "120/120 [==============================] - 0s 218us/sample - loss: 0.6056 - accuracy: 0.7333 - val_loss: 0.6637 - val_accuracy: 0.7000\n",
      "Epoch 184/300\n",
      "120/120 [==============================] - 0s 212us/sample - loss: 0.6041 - accuracy: 0.7333 - val_loss: 0.6621 - val_accuracy: 0.7000\n",
      "Epoch 185/300\n",
      "120/120 [==============================] - 0s 232us/sample - loss: 0.6026 - accuracy: 0.7250 - val_loss: 0.6604 - val_accuracy: 0.7000\n",
      "Epoch 186/300\n",
      "120/120 [==============================] - 0s 170us/sample - loss: 0.6012 - accuracy: 0.7250 - val_loss: 0.6592 - val_accuracy: 0.7000\n",
      "Epoch 187/300\n",
      "120/120 [==============================] - 0s 172us/sample - loss: 0.5996 - accuracy: 0.7250 - val_loss: 0.6574 - val_accuracy: 0.7000\n",
      "Epoch 188/300\n",
      "120/120 [==============================] - 0s 113us/sample - loss: 0.5981 - accuracy: 0.7250 - val_loss: 0.6562 - val_accuracy: 0.7000\n",
      "Epoch 189/300\n",
      "120/120 [==============================] - 0s 135us/sample - loss: 0.5966 - accuracy: 0.7250 - val_loss: 0.6546 - val_accuracy: 0.7000\n",
      "Epoch 190/300\n",
      "120/120 [==============================] - 0s 103us/sample - loss: 0.5950 - accuracy: 0.7250 - val_loss: 0.6530 - val_accuracy: 0.7000\n",
      "Epoch 191/300\n",
      "120/120 [==============================] - 0s 126us/sample - loss: 0.5936 - accuracy: 0.7250 - val_loss: 0.6515 - val_accuracy: 0.7000\n",
      "Epoch 192/300\n",
      "120/120 [==============================] - 0s 156us/sample - loss: 0.5921 - accuracy: 0.7250 - val_loss: 0.6501 - val_accuracy: 0.7333\n",
      "Epoch 193/300\n",
      "120/120 [==============================] - 0s 113us/sample - loss: 0.5907 - accuracy: 0.7250 - val_loss: 0.6488 - val_accuracy: 0.7000\n",
      "Epoch 194/300\n",
      "120/120 [==============================] - 0s 157us/sample - loss: 0.5891 - accuracy: 0.7250 - val_loss: 0.6470 - val_accuracy: 0.7333\n",
      "Epoch 195/300\n",
      "120/120 [==============================] - 0s 213us/sample - loss: 0.5877 - accuracy: 0.7417 - val_loss: 0.6454 - val_accuracy: 0.7333\n",
      "Epoch 196/300\n",
      "120/120 [==============================] - 0s 182us/sample - loss: 0.5863 - accuracy: 0.7417 - val_loss: 0.6440 - val_accuracy: 0.7333\n",
      "Epoch 197/300\n",
      "120/120 [==============================] - 0s 153us/sample - loss: 0.5848 - accuracy: 0.7417 - val_loss: 0.6425 - val_accuracy: 0.7333\n",
      "Epoch 198/300\n",
      "120/120 [==============================] - 0s 124us/sample - loss: 0.5834 - accuracy: 0.7417 - val_loss: 0.6411 - val_accuracy: 0.7333\n",
      "Epoch 199/300\n",
      "120/120 [==============================] - 0s 106us/sample - loss: 0.5820 - accuracy: 0.7417 - val_loss: 0.6396 - val_accuracy: 0.7333\n",
      "Epoch 200/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.5806 - accuracy: 0.7417 - val_loss: 0.6381 - val_accuracy: 0.7333\n",
      "Epoch 201/300\n",
      "120/120 [==============================] - 0s 119us/sample - loss: 0.5792 - accuracy: 0.7417 - val_loss: 0.6366 - val_accuracy: 0.7333\n",
      "Epoch 202/300\n",
      "120/120 [==============================] - 0s 114us/sample - loss: 0.5778 - accuracy: 0.7417 - val_loss: 0.6353 - val_accuracy: 0.7333\n",
      "Epoch 203/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.5764 - accuracy: 0.7417 - val_loss: 0.6341 - val_accuracy: 0.7333\n",
      "Epoch 204/300\n",
      "120/120 [==============================] - 0s 101us/sample - loss: 0.5750 - accuracy: 0.7417 - val_loss: 0.6330 - val_accuracy: 0.7333\n",
      "Epoch 205/300\n",
      "120/120 [==============================] - 0s 99us/sample - loss: 0.5737 - accuracy: 0.7417 - val_loss: 0.6320 - val_accuracy: 0.7333\n",
      "Epoch 206/300\n",
      "120/120 [==============================] - 0s 106us/sample - loss: 0.5724 - accuracy: 0.7417 - val_loss: 0.6309 - val_accuracy: 0.7333\n",
      "Epoch 207/300\n",
      "120/120 [==============================] - 0s 130us/sample - loss: 0.5709 - accuracy: 0.7417 - val_loss: 0.6295 - val_accuracy: 0.7333\n",
      "Epoch 208/300\n",
      "120/120 [==============================] - 0s 115us/sample - loss: 0.5696 - accuracy: 0.7417 - val_loss: 0.6281 - val_accuracy: 0.7333\n",
      "Epoch 209/300\n",
      "120/120 [==============================] - 0s 112us/sample - loss: 0.5684 - accuracy: 0.7417 - val_loss: 0.6263 - val_accuracy: 0.7333\n",
      "Epoch 210/300\n",
      "120/120 [==============================] - 0s 94us/sample - loss: 0.5670 - accuracy: 0.7417 - val_loss: 0.6247 - val_accuracy: 0.7333\n",
      "Epoch 211/300\n",
      "120/120 [==============================] - 0s 107us/sample - loss: 0.5656 - accuracy: 0.7417 - val_loss: 0.6233 - val_accuracy: 0.7333\n",
      "Epoch 212/300\n",
      "120/120 [==============================] - 0s 151us/sample - loss: 0.5643 - accuracy: 0.7417 - val_loss: 0.6220 - val_accuracy: 0.7333\n",
      "Epoch 213/300\n",
      "120/120 [==============================] - 0s 182us/sample - loss: 0.5633 - accuracy: 0.7417 - val_loss: 0.6212 - val_accuracy: 0.7333\n",
      "Epoch 214/300\n",
      "120/120 [==============================] - 0s 88us/sample - loss: 0.5617 - accuracy: 0.7417 - val_loss: 0.6199 - val_accuracy: 0.7333\n",
      "Epoch 215/300\n",
      "120/120 [==============================] - 0s 79us/sample - loss: 0.5605 - accuracy: 0.7417 - val_loss: 0.6187 - val_accuracy: 0.7333\n",
      "Epoch 216/300\n",
      "120/120 [==============================] - 0s 72us/sample - loss: 0.5592 - accuracy: 0.7417 - val_loss: 0.6172 - val_accuracy: 0.7333\n",
      "Epoch 217/300\n",
      "120/120 [==============================] - 0s 76us/sample - loss: 0.5579 - accuracy: 0.7417 - val_loss: 0.6159 - val_accuracy: 0.7333\n",
      "Epoch 218/300\n",
      "120/120 [==============================] - 0s 90us/sample - loss: 0.5566 - accuracy: 0.7417 - val_loss: 0.6149 - val_accuracy: 0.7333\n",
      "Epoch 219/300\n",
      "120/120 [==============================] - 0s 173us/sample - loss: 0.5554 - accuracy: 0.7417 - val_loss: 0.6137 - val_accuracy: 0.7333\n",
      "Epoch 220/300\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 0.5543 - accuracy: 0.7417 - val_loss: 0.6130 - val_accuracy: 0.7333\n",
      "Epoch 221/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 131us/sample - loss: 0.5529 - accuracy: 0.7417 - val_loss: 0.6117 - val_accuracy: 0.7333\n",
      "Epoch 222/300\n",
      "120/120 [==============================] - 0s 127us/sample - loss: 0.5517 - accuracy: 0.7417 - val_loss: 0.6103 - val_accuracy: 0.7333\n",
      "Epoch 223/300\n",
      "120/120 [==============================] - 0s 96us/sample - loss: 0.5505 - accuracy: 0.7417 - val_loss: 0.6090 - val_accuracy: 0.7333\n",
      "Epoch 224/300\n",
      "120/120 [==============================] - 0s 105us/sample - loss: 0.5493 - accuracy: 0.7417 - val_loss: 0.6076 - val_accuracy: 0.7333\n",
      "Epoch 225/300\n",
      "120/120 [==============================] - 0s 116us/sample - loss: 0.5480 - accuracy: 0.7417 - val_loss: 0.6065 - val_accuracy: 0.7333\n",
      "Epoch 226/300\n",
      "120/120 [==============================] - 0s 127us/sample - loss: 0.5469 - accuracy: 0.7417 - val_loss: 0.6055 - val_accuracy: 0.7333\n",
      "Epoch 227/300\n",
      "120/120 [==============================] - 0s 128us/sample - loss: 0.5457 - accuracy: 0.7417 - val_loss: 0.6041 - val_accuracy: 0.7333\n",
      "Epoch 228/300\n",
      "120/120 [==============================] - 0s 111us/sample - loss: 0.5444 - accuracy: 0.7417 - val_loss: 0.6028 - val_accuracy: 0.7333\n",
      "Epoch 229/300\n",
      "120/120 [==============================] - 0s 114us/sample - loss: 0.5433 - accuracy: 0.7500 - val_loss: 0.6015 - val_accuracy: 0.7333\n",
      "Epoch 230/300\n",
      "120/120 [==============================] - 0s 131us/sample - loss: 0.5421 - accuracy: 0.7500 - val_loss: 0.6002 - val_accuracy: 0.7333\n",
      "Epoch 231/300\n",
      "120/120 [==============================] - 0s 118us/sample - loss: 0.5411 - accuracy: 0.7500 - val_loss: 0.5986 - val_accuracy: 0.7333\n",
      "Epoch 232/300\n",
      "120/120 [==============================] - 0s 115us/sample - loss: 0.5398 - accuracy: 0.7500 - val_loss: 0.5974 - val_accuracy: 0.7333\n",
      "Epoch 233/300\n",
      "120/120 [==============================] - 0s 97us/sample - loss: 0.5386 - accuracy: 0.7500 - val_loss: 0.5963 - val_accuracy: 0.7333\n",
      "Epoch 234/300\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.5374 - accuracy: 0.7500 - val_loss: 0.5952 - val_accuracy: 0.7333\n",
      "Epoch 235/300\n",
      "120/120 [==============================] - 0s 127us/sample - loss: 0.5363 - accuracy: 0.7500 - val_loss: 0.5940 - val_accuracy: 0.7333\n",
      "Epoch 236/300\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.4940 - accuracy: 0.81 - 0s 171us/sample - loss: 0.5352 - accuracy: 0.7500 - val_loss: 0.5931 - val_accuracy: 0.7333\n",
      "Epoch 237/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.5340 - accuracy: 0.7500 - val_loss: 0.5920 - val_accuracy: 0.7333\n",
      "Epoch 238/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.5329 - accuracy: 0.7500 - val_loss: 0.5908 - val_accuracy: 0.7333\n",
      "Epoch 239/300\n",
      "120/120 [==============================] - 0s 163us/sample - loss: 0.5318 - accuracy: 0.7500 - val_loss: 0.5894 - val_accuracy: 0.7333\n",
      "Epoch 240/300\n",
      "120/120 [==============================] - 0s 87us/sample - loss: 0.5309 - accuracy: 0.7500 - val_loss: 0.5886 - val_accuracy: 0.7333\n",
      "Epoch 241/300\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.5296 - accuracy: 0.7500 - val_loss: 0.5874 - val_accuracy: 0.7333\n",
      "Epoch 242/300\n",
      "120/120 [==============================] - 0s 159us/sample - loss: 0.5287 - accuracy: 0.7500 - val_loss: 0.5857 - val_accuracy: 0.7333\n",
      "Epoch 243/300\n",
      "120/120 [==============================] - 0s 214us/sample - loss: 0.5275 - accuracy: 0.7500 - val_loss: 0.5847 - val_accuracy: 0.7333\n",
      "Epoch 244/300\n",
      "120/120 [==============================] - 0s 394us/sample - loss: 0.5264 - accuracy: 0.7500 - val_loss: 0.5835 - val_accuracy: 0.7667\n",
      "Epoch 245/300\n",
      "120/120 [==============================] - 0s 135us/sample - loss: 0.5252 - accuracy: 0.7500 - val_loss: 0.5825 - val_accuracy: 0.7667\n",
      "Epoch 246/300\n",
      "120/120 [==============================] - 0s 168us/sample - loss: 0.5242 - accuracy: 0.7500 - val_loss: 0.5813 - val_accuracy: 0.7667\n",
      "Epoch 247/300\n",
      "120/120 [==============================] - 0s 105us/sample - loss: 0.5231 - accuracy: 0.7500 - val_loss: 0.5802 - val_accuracy: 0.7667\n",
      "Epoch 248/300\n",
      "120/120 [==============================] - 0s 178us/sample - loss: 0.5221 - accuracy: 0.7500 - val_loss: 0.5793 - val_accuracy: 0.7667\n",
      "Epoch 249/300\n",
      "120/120 [==============================] - 0s 191us/sample - loss: 0.5212 - accuracy: 0.7500 - val_loss: 0.5784 - val_accuracy: 0.7667\n",
      "Epoch 250/300\n",
      "120/120 [==============================] - 0s 152us/sample - loss: 0.5200 - accuracy: 0.7500 - val_loss: 0.5771 - val_accuracy: 0.7667\n",
      "Epoch 251/300\n",
      "120/120 [==============================] - 0s 148us/sample - loss: 0.5190 - accuracy: 0.7583 - val_loss: 0.5758 - val_accuracy: 0.7667\n",
      "Epoch 252/300\n",
      "120/120 [==============================] - 0s 124us/sample - loss: 0.5182 - accuracy: 0.7667 - val_loss: 0.5744 - val_accuracy: 0.7667\n",
      "Epoch 253/300\n",
      "120/120 [==============================] - 0s 119us/sample - loss: 0.5170 - accuracy: 0.7667 - val_loss: 0.5737 - val_accuracy: 0.7667\n",
      "Epoch 254/300\n",
      "120/120 [==============================] - 0s 135us/sample - loss: 0.5160 - accuracy: 0.7583 - val_loss: 0.5729 - val_accuracy: 0.7667\n",
      "Epoch 255/300\n",
      "120/120 [==============================] - 0s 123us/sample - loss: 0.5151 - accuracy: 0.7583 - val_loss: 0.5722 - val_accuracy: 0.7667\n",
      "Epoch 256/300\n",
      "120/120 [==============================] - 0s 157us/sample - loss: 0.5143 - accuracy: 0.7583 - val_loss: 0.5716 - val_accuracy: 0.7667\n",
      "Epoch 257/300\n",
      "120/120 [==============================] - 0s 144us/sample - loss: 0.5131 - accuracy: 0.7583 - val_loss: 0.5702 - val_accuracy: 0.7667\n",
      "Epoch 258/300\n",
      "120/120 [==============================] - 0s 132us/sample - loss: 0.5122 - accuracy: 0.7667 - val_loss: 0.5689 - val_accuracy: 0.7667\n",
      "Epoch 259/300\n",
      "120/120 [==============================] - 0s 180us/sample - loss: 0.5111 - accuracy: 0.7583 - val_loss: 0.5680 - val_accuracy: 0.7667\n",
      "Epoch 260/300\n",
      "120/120 [==============================] - 0s 181us/sample - loss: 0.5102 - accuracy: 0.7583 - val_loss: 0.5672 - val_accuracy: 0.7667\n",
      "Epoch 261/300\n",
      "120/120 [==============================] - 0s 122us/sample - loss: 0.5091 - accuracy: 0.7583 - val_loss: 0.5662 - val_accuracy: 0.7667\n",
      "Epoch 262/300\n",
      "120/120 [==============================] - 0s 130us/sample - loss: 0.5082 - accuracy: 0.7667 - val_loss: 0.5651 - val_accuracy: 0.7667\n",
      "Epoch 263/300\n",
      "120/120 [==============================] - 0s 156us/sample - loss: 0.5074 - accuracy: 0.7667 - val_loss: 0.5639 - val_accuracy: 0.7667\n",
      "Epoch 264/300\n",
      "120/120 [==============================] - 0s 122us/sample - loss: 0.5063 - accuracy: 0.7667 - val_loss: 0.5630 - val_accuracy: 0.7667\n",
      "Epoch 265/300\n",
      "120/120 [==============================] - 0s 113us/sample - loss: 0.5055 - accuracy: 0.7667 - val_loss: 0.5621 - val_accuracy: 0.7667\n",
      "Epoch 266/300\n",
      "120/120 [==============================] - 0s 107us/sample - loss: 0.5045 - accuracy: 0.7667 - val_loss: 0.5611 - val_accuracy: 0.7667\n",
      "Epoch 267/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.5036 - accuracy: 0.7667 - val_loss: 0.5600 - val_accuracy: 0.7667\n",
      "Epoch 268/300\n",
      "120/120 [==============================] - 0s 105us/sample - loss: 0.5027 - accuracy: 0.7667 - val_loss: 0.5592 - val_accuracy: 0.7667\n",
      "Epoch 269/300\n",
      "120/120 [==============================] - 0s 111us/sample - loss: 0.5018 - accuracy: 0.7667 - val_loss: 0.5584 - val_accuracy: 0.7667\n",
      "Epoch 270/300\n",
      "120/120 [==============================] - 0s 137us/sample - loss: 0.5009 - accuracy: 0.7667 - val_loss: 0.5572 - val_accuracy: 0.7667\n",
      "Epoch 271/300\n",
      "120/120 [==============================] - 0s 146us/sample - loss: 0.5002 - accuracy: 0.7667 - val_loss: 0.5560 - val_accuracy: 0.7667\n",
      "Epoch 272/300\n",
      "120/120 [==============================] - 0s 134us/sample - loss: 0.4992 - accuracy: 0.7667 - val_loss: 0.5550 - val_accuracy: 0.7667\n",
      "Epoch 273/300\n",
      "120/120 [==============================] - 0s 143us/sample - loss: 0.4982 - accuracy: 0.7667 - val_loss: 0.5544 - val_accuracy: 0.7667\n",
      "Epoch 274/300\n",
      "120/120 [==============================] - 0s 136us/sample - loss: 0.4974 - accuracy: 0.7667 - val_loss: 0.5540 - val_accuracy: 0.7667\n",
      "Epoch 275/300\n",
      "120/120 [==============================] - 0s 171us/sample - loss: 0.4966 - accuracy: 0.7667 - val_loss: 0.5535 - val_accuracy: 0.7667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 276/300\n",
      "120/120 [==============================] - 0s 173us/sample - loss: 0.4957 - accuracy: 0.7667 - val_loss: 0.5527 - val_accuracy: 0.7667\n",
      "Epoch 277/300\n",
      "120/120 [==============================] - 0s 170us/sample - loss: 0.4948 - accuracy: 0.7667 - val_loss: 0.5517 - val_accuracy: 0.7667\n",
      "Epoch 278/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.4940 - accuracy: 0.7667 - val_loss: 0.5508 - val_accuracy: 0.7667\n",
      "Epoch 279/300\n",
      "120/120 [==============================] - 0s 203us/sample - loss: 0.4932 - accuracy: 0.7667 - val_loss: 0.5504 - val_accuracy: 0.7667\n",
      "Epoch 280/300\n",
      "120/120 [==============================] - 0s 158us/sample - loss: 0.4923 - accuracy: 0.7667 - val_loss: 0.5496 - val_accuracy: 0.7667\n",
      "Epoch 281/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.4915 - accuracy: 0.7667 - val_loss: 0.5489 - val_accuracy: 0.7667\n",
      "Epoch 282/300\n",
      "120/120 [==============================] - 0s 198us/sample - loss: 0.4906 - accuracy: 0.7667 - val_loss: 0.5478 - val_accuracy: 0.7667\n",
      "Epoch 283/300\n",
      "120/120 [==============================] - 0s 163us/sample - loss: 0.4900 - accuracy: 0.7667 - val_loss: 0.5467 - val_accuracy: 0.7667\n",
      "Epoch 284/300\n",
      "120/120 [==============================] - 0s 157us/sample - loss: 0.4890 - accuracy: 0.7667 - val_loss: 0.5458 - val_accuracy: 0.7667\n",
      "Epoch 285/300\n",
      "120/120 [==============================] - 0s 167us/sample - loss: 0.4882 - accuracy: 0.7667 - val_loss: 0.5448 - val_accuracy: 0.7667\n",
      "Epoch 286/300\n",
      "120/120 [==============================] - 0s 210us/sample - loss: 0.4875 - accuracy: 0.7667 - val_loss: 0.5443 - val_accuracy: 0.7667\n",
      "Epoch 287/300\n",
      "120/120 [==============================] - 0s 177us/sample - loss: 0.4866 - accuracy: 0.7667 - val_loss: 0.5433 - val_accuracy: 0.7667\n",
      "Epoch 288/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.4858 - accuracy: 0.7667 - val_loss: 0.5423 - val_accuracy: 0.7667\n",
      "Epoch 289/300\n",
      "120/120 [==============================] - 0s 223us/sample - loss: 0.4850 - accuracy: 0.7667 - val_loss: 0.5416 - val_accuracy: 0.7667\n",
      "Epoch 290/300\n",
      "120/120 [==============================] - 0s 272us/sample - loss: 0.4842 - accuracy: 0.7667 - val_loss: 0.5404 - val_accuracy: 0.7667\n",
      "Epoch 291/300\n",
      "120/120 [==============================] - 0s 144us/sample - loss: 0.4834 - accuracy: 0.7667 - val_loss: 0.5393 - val_accuracy: 0.7667\n",
      "Epoch 292/300\n",
      "120/120 [==============================] - 0s 183us/sample - loss: 0.4827 - accuracy: 0.7667 - val_loss: 0.5382 - val_accuracy: 0.7667\n",
      "Epoch 293/300\n",
      "120/120 [==============================] - 0s 153us/sample - loss: 0.4819 - accuracy: 0.7667 - val_loss: 0.5374 - val_accuracy: 0.7667\n",
      "Epoch 294/300\n",
      "120/120 [==============================] - 0s 129us/sample - loss: 0.4811 - accuracy: 0.7667 - val_loss: 0.5364 - val_accuracy: 0.7667\n",
      "Epoch 295/300\n",
      "120/120 [==============================] - 0s 146us/sample - loss: 0.4804 - accuracy: 0.7667 - val_loss: 0.5357 - val_accuracy: 0.7667\n",
      "Epoch 296/300\n",
      "120/120 [==============================] - 0s 139us/sample - loss: 0.4796 - accuracy: 0.7667 - val_loss: 0.5348 - val_accuracy: 0.7667\n",
      "Epoch 297/300\n",
      "120/120 [==============================] - 0s 136us/sample - loss: 0.4788 - accuracy: 0.7667 - val_loss: 0.5339 - val_accuracy: 0.7667\n",
      "Epoch 298/300\n",
      "120/120 [==============================] - 0s 152us/sample - loss: 0.4783 - accuracy: 0.7750 - val_loss: 0.5328 - val_accuracy: 0.7667\n",
      "Epoch 299/300\n",
      "120/120 [==============================] - 0s 146us/sample - loss: 0.4774 - accuracy: 0.7750 - val_loss: 0.5324 - val_accuracy: 0.7667\n",
      "Epoch 300/300\n",
      "120/120 [==============================] - 0s 114us/sample - loss: 0.4766 - accuracy: 0.7750 - val_loss: 0.5317 - val_accuracy: 0.7667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13d39d978>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=scaled_X_train, y=y_train, epochs=300,\n",
    "         validation_data=(scaled_X_test, y_test),\n",
    "         callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x13dde73c8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['loss', 'val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x140032a58>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['accuracy', 'val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.531663179397583, 0.76666665]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(scaled_X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = len(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4, activation='relu', input_shape=[4,]))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 150 samples\n",
      "Epoch 1/300\n",
      "150/150 [==============================] - 0s 2ms/sample - loss: 1.0669 - accuracy: 0.3400\n",
      "Epoch 2/300\n",
      "150/150 [==============================] - 0s 56us/sample - loss: 1.0643 - accuracy: 0.3400\n",
      "Epoch 3/300\n",
      "150/150 [==============================] - 0s 70us/sample - loss: 1.0617 - accuracy: 0.3333\n",
      "Epoch 4/300\n",
      "150/150 [==============================] - 0s 92us/sample - loss: 1.0589 - accuracy: 0.3333\n",
      "Epoch 5/300\n",
      "150/150 [==============================] - 0s 70us/sample - loss: 1.0565 - accuracy: 0.3333\n",
      "Epoch 6/300\n",
      "150/150 [==============================] - 0s 125us/sample - loss: 1.0538 - accuracy: 0.3333\n",
      "Epoch 7/300\n",
      "150/150 [==============================] - 0s 71us/sample - loss: 1.0515 - accuracy: 0.3333\n",
      "Epoch 8/300\n",
      "150/150 [==============================] - 0s 78us/sample - loss: 1.0487 - accuracy: 0.3333\n",
      "Epoch 9/300\n",
      "150/150 [==============================] - 0s 146us/sample - loss: 1.0465 - accuracy: 0.3333\n",
      "Epoch 10/300\n",
      "150/150 [==============================] - 0s 146us/sample - loss: 1.0435 - accuracy: 0.3333\n",
      "Epoch 11/300\n",
      "150/150 [==============================] - 0s 89us/sample - loss: 1.0408 - accuracy: 0.3333\n",
      "Epoch 12/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 1.0385 - accuracy: 0.3333\n",
      "Epoch 13/300\n",
      "150/150 [==============================] - 0s 122us/sample - loss: 1.0353 - accuracy: 0.3333\n",
      "Epoch 14/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 1.0322 - accuracy: 0.3400\n",
      "Epoch 15/300\n",
      "150/150 [==============================] - 0s 72us/sample - loss: 1.0291 - accuracy: 0.3400\n",
      "Epoch 16/300\n",
      "150/150 [==============================] - 0s 89us/sample - loss: 1.0259 - accuracy: 0.3400\n",
      "Epoch 17/300\n",
      "150/150 [==============================] - 0s 91us/sample - loss: 1.0224 - accuracy: 0.3467\n",
      "Epoch 18/300\n",
      "150/150 [==============================] - 0s 66us/sample - loss: 1.0186 - accuracy: 0.3467\n",
      "Epoch 19/300\n",
      "150/150 [==============================] - 0s 77us/sample - loss: 1.0149 - accuracy: 0.3533\n",
      "Epoch 20/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 1.0109 - accuracy: 0.3600\n",
      "Epoch 21/300\n",
      "150/150 [==============================] - 0s 96us/sample - loss: 1.0067 - accuracy: 0.3600\n",
      "Epoch 22/300\n",
      "150/150 [==============================] - 0s 102us/sample - loss: 1.0027 - accuracy: 0.3800\n",
      "Epoch 23/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.9986 - accuracy: 0.3800\n",
      "Epoch 24/300\n",
      "150/150 [==============================] - 0s 88us/sample - loss: 0.9943 - accuracy: 0.4067\n",
      "Epoch 25/300\n",
      "150/150 [==============================] - 0s 111us/sample - loss: 0.9900 - accuracy: 0.4267\n",
      "Epoch 26/300\n",
      "150/150 [==============================] - 0s 124us/sample - loss: 0.9857 - accuracy: 0.4400\n",
      "Epoch 27/300\n",
      "150/150 [==============================] - 0s 141us/sample - loss: 0.9812 - accuracy: 0.4533\n",
      "Epoch 28/300\n",
      "150/150 [==============================] - 0s 82us/sample - loss: 0.9767 - accuracy: 0.4733\n",
      "Epoch 29/300\n",
      "150/150 [==============================] - 0s 70us/sample - loss: 0.9719 - accuracy: 0.4867\n",
      "Epoch 30/300\n",
      "150/150 [==============================] - 0s 119us/sample - loss: 0.9671 - accuracy: 0.4933\n",
      "Epoch 31/300\n",
      "150/150 [==============================] - 0s 66us/sample - loss: 0.9621 - accuracy: 0.5133\n",
      "Epoch 32/300\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.9785 - accuracy: 0.50 - 0s 118us/sample - loss: 0.9571 - accuracy: 0.5200\n",
      "Epoch 33/300\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.9521 - accuracy: 0.5333\n",
      "Epoch 34/300\n",
      "150/150 [==============================] - 0s 130us/sample - loss: 0.9467 - accuracy: 0.5600\n",
      "Epoch 35/300\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.9416 - accuracy: 0.5667\n",
      "Epoch 36/300\n",
      "150/150 [==============================] - 0s 103us/sample - loss: 0.9360 - accuracy: 0.5867\n",
      "Epoch 37/300\n",
      "150/150 [==============================] - 0s 95us/sample - loss: 0.9307 - accuracy: 0.5933\n",
      "Epoch 38/300\n",
      "150/150 [==============================] - 0s 65us/sample - loss: 0.9252 - accuracy: 0.6067\n",
      "Epoch 39/300\n",
      "150/150 [==============================] - 0s 55us/sample - loss: 0.9194 - accuracy: 0.6133\n",
      "Epoch 40/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.9137 - accuracy: 0.6400\n",
      "Epoch 41/300\n",
      "150/150 [==============================] - 0s 91us/sample - loss: 0.9083 - accuracy: 0.6400\n",
      "Epoch 42/300\n",
      "150/150 [==============================] - 0s 76us/sample - loss: 0.9021 - accuracy: 0.6533\n",
      "Epoch 43/300\n",
      "150/150 [==============================] - 0s 92us/sample - loss: 0.8962 - accuracy: 0.6600\n",
      "Epoch 44/300\n",
      "150/150 [==============================] - 0s 104us/sample - loss: 0.8904 - accuracy: 0.6667\n",
      "Epoch 45/300\n",
      "150/150 [==============================] - 0s 96us/sample - loss: 0.8844 - accuracy: 0.6667\n",
      "Epoch 46/300\n",
      "150/150 [==============================] - 0s 82us/sample - loss: 0.8784 - accuracy: 0.6667\n",
      "Epoch 47/300\n",
      "150/150 [==============================] - 0s 110us/sample - loss: 0.8723 - accuracy: 0.6667\n",
      "Epoch 48/300\n",
      "150/150 [==============================] - 0s 94us/sample - loss: 0.8663 - accuracy: 0.6733\n",
      "Epoch 49/300\n",
      "150/150 [==============================] - 0s 98us/sample - loss: 0.8601 - accuracy: 0.6733\n",
      "Epoch 50/300\n",
      "150/150 [==============================] - 0s 94us/sample - loss: 0.8540 - accuracy: 0.6733\n",
      "Epoch 51/300\n",
      "150/150 [==============================] - 0s 95us/sample - loss: 0.8479 - accuracy: 0.6733\n",
      "Epoch 52/300\n",
      "150/150 [==============================] - 0s 79us/sample - loss: 0.8416 - accuracy: 0.6733\n",
      "Epoch 53/300\n",
      "150/150 [==============================] - 0s 66us/sample - loss: 0.8355 - accuracy: 0.6733\n",
      "Epoch 54/300\n",
      "150/150 [==============================] - 0s 81us/sample - loss: 0.8292 - accuracy: 0.6733\n",
      "Epoch 55/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.8232 - accuracy: 0.6733\n",
      "Epoch 56/300\n",
      "150/150 [==============================] - 0s 109us/sample - loss: 0.8170 - accuracy: 0.6733\n",
      "Epoch 57/300\n",
      "150/150 [==============================] - 0s 117us/sample - loss: 0.8109 - accuracy: 0.6800\n",
      "Epoch 58/300\n",
      "150/150 [==============================] - 0s 91us/sample - loss: 0.8048 - accuracy: 0.6867\n",
      "Epoch 59/300\n",
      "150/150 [==============================] - 0s 96us/sample - loss: 0.7985 - accuracy: 0.6867\n",
      "Epoch 60/300\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.7925 - accuracy: 0.6867\n",
      "Epoch 61/300\n",
      "150/150 [==============================] - 0s 54us/sample - loss: 0.7865 - accuracy: 0.6867\n",
      "Epoch 62/300\n",
      "150/150 [==============================] - 0s 65us/sample - loss: 0.7806 - accuracy: 0.6867\n",
      "Epoch 63/300\n",
      "150/150 [==============================] - 0s 79us/sample - loss: 0.7744 - accuracy: 0.6867\n",
      "Epoch 64/300\n",
      "150/150 [==============================] - 0s 70us/sample - loss: 0.7686 - accuracy: 0.6867\n",
      "Epoch 65/300\n",
      "150/150 [==============================] - 0s 110us/sample - loss: 0.7629 - accuracy: 0.6867\n",
      "Epoch 66/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.7568 - accuracy: 0.6867\n",
      "Epoch 67/300\n",
      "150/150 [==============================] - 0s 92us/sample - loss: 0.7512 - accuracy: 0.6867\n",
      "Epoch 68/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.7456 - accuracy: 0.6867\n",
      "Epoch 69/300\n",
      "150/150 [==============================] - 0s 112us/sample - loss: 0.7398 - accuracy: 0.6867\n",
      "Epoch 70/300\n",
      "150/150 [==============================] - 0s 96us/sample - loss: 0.7342 - accuracy: 0.6867\n",
      "Epoch 71/300\n",
      "150/150 [==============================] - 0s 94us/sample - loss: 0.7286 - accuracy: 0.6867\n",
      "Epoch 72/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.7231 - accuracy: 0.6867\n",
      "Epoch 73/300\n",
      "150/150 [==============================] - 0s 89us/sample - loss: 0.7177 - accuracy: 0.6867\n",
      "Epoch 74/300\n",
      "150/150 [==============================] - 0s 78us/sample - loss: 0.7122 - accuracy: 0.6867\n",
      "Epoch 75/300\n",
      "150/150 [==============================] - 0s 88us/sample - loss: 0.7071 - accuracy: 0.6867\n",
      "Epoch 76/300\n",
      "150/150 [==============================] - 0s 101us/sample - loss: 0.7018 - accuracy: 0.6867\n",
      "Epoch 77/300\n",
      "150/150 [==============================] - 0s 115us/sample - loss: 0.6966 - accuracy: 0.6867\n",
      "Epoch 78/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 92us/sample - loss: 0.6915 - accuracy: 0.6867\n",
      "Epoch 79/300\n",
      "150/150 [==============================] - 0s 85us/sample - loss: 0.6865 - accuracy: 0.6867\n",
      "Epoch 80/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.6816 - accuracy: 0.6933\n",
      "Epoch 81/300\n",
      "150/150 [==============================] - 0s 89us/sample - loss: 0.6767 - accuracy: 0.7000\n",
      "Epoch 82/300\n",
      "150/150 [==============================] - 0s 84us/sample - loss: 0.6722 - accuracy: 0.7000\n",
      "Epoch 83/300\n",
      "150/150 [==============================] - 0s 75us/sample - loss: 0.6672 - accuracy: 0.7000\n",
      "Epoch 84/300\n",
      "150/150 [==============================] - 0s 74us/sample - loss: 0.6625 - accuracy: 0.7000\n",
      "Epoch 85/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.6580 - accuracy: 0.7000\n",
      "Epoch 86/300\n",
      "150/150 [==============================] - 0s 72us/sample - loss: 0.6536 - accuracy: 0.7000\n",
      "Epoch 87/300\n",
      "150/150 [==============================] - 0s 84us/sample - loss: 0.6492 - accuracy: 0.7000\n",
      "Epoch 88/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.6448 - accuracy: 0.7000\n",
      "Epoch 89/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.6406 - accuracy: 0.7000\n",
      "Epoch 90/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.6364 - accuracy: 0.7067\n",
      "Epoch 91/300\n",
      "150/150 [==============================] - 0s 75us/sample - loss: 0.6322 - accuracy: 0.7067\n",
      "Epoch 92/300\n",
      "150/150 [==============================] - 0s 69us/sample - loss: 0.6281 - accuracy: 0.7067\n",
      "Epoch 93/300\n",
      "150/150 [==============================] - 0s 77us/sample - loss: 0.6241 - accuracy: 0.7133\n",
      "Epoch 94/300\n",
      "150/150 [==============================] - 0s 92us/sample - loss: 0.6203 - accuracy: 0.7133\n",
      "Epoch 95/300\n",
      "150/150 [==============================] - 0s 66us/sample - loss: 0.6164 - accuracy: 0.7200\n",
      "Epoch 96/300\n",
      "150/150 [==============================] - 0s 49us/sample - loss: 0.6127 - accuracy: 0.7200\n",
      "Epoch 97/300\n",
      "150/150 [==============================] - 0s 88us/sample - loss: 0.6090 - accuracy: 0.7200\n",
      "Epoch 98/300\n",
      "150/150 [==============================] - 0s 71us/sample - loss: 0.6054 - accuracy: 0.7200\n",
      "Epoch 99/300\n",
      "150/150 [==============================] - 0s 46us/sample - loss: 0.6017 - accuracy: 0.7200\n",
      "Epoch 100/300\n",
      "150/150 [==============================] - 0s 62us/sample - loss: 0.5982 - accuracy: 0.7200\n",
      "Epoch 101/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.5948 - accuracy: 0.7200\n",
      "Epoch 102/300\n",
      "150/150 [==============================] - 0s 68us/sample - loss: 0.5914 - accuracy: 0.7200\n",
      "Epoch 103/300\n",
      "150/150 [==============================] - 0s 94us/sample - loss: 0.5880 - accuracy: 0.7267\n",
      "Epoch 104/300\n",
      "150/150 [==============================] - 0s 84us/sample - loss: 0.5848 - accuracy: 0.7267\n",
      "Epoch 105/300\n",
      "150/150 [==============================] - 0s 71us/sample - loss: 0.5815 - accuracy: 0.7267\n",
      "Epoch 106/300\n",
      "150/150 [==============================] - 0s 70us/sample - loss: 0.5784 - accuracy: 0.7267\n",
      "Epoch 107/300\n",
      "150/150 [==============================] - 0s 97us/sample - loss: 0.5753 - accuracy: 0.7267\n",
      "Epoch 108/300\n",
      "150/150 [==============================] - 0s 91us/sample - loss: 0.5721 - accuracy: 0.7267\n",
      "Epoch 109/300\n",
      "150/150 [==============================] - 0s 72us/sample - loss: 0.5692 - accuracy: 0.7267\n",
      "Epoch 110/300\n",
      "150/150 [==============================] - 0s 112us/sample - loss: 0.5662 - accuracy: 0.7333\n",
      "Epoch 111/300\n",
      "150/150 [==============================] - 0s 123us/sample - loss: 0.5633 - accuracy: 0.7333\n",
      "Epoch 112/300\n",
      "150/150 [==============================] - 0s 126us/sample - loss: 0.5606 - accuracy: 0.7333\n",
      "Epoch 113/300\n",
      "150/150 [==============================] - 0s 175us/sample - loss: 0.5577 - accuracy: 0.7333\n",
      "Epoch 114/300\n",
      "150/150 [==============================] - 0s 124us/sample - loss: 0.5549 - accuracy: 0.7333\n",
      "Epoch 115/300\n",
      "150/150 [==============================] - 0s 91us/sample - loss: 0.5522 - accuracy: 0.7400\n",
      "Epoch 116/300\n",
      "150/150 [==============================] - 0s 71us/sample - loss: 0.5496 - accuracy: 0.7400\n",
      "Epoch 117/300\n",
      "150/150 [==============================] - 0s 91us/sample - loss: 0.5469 - accuracy: 0.7467\n",
      "Epoch 118/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5444 - accuracy: 0.7467\n",
      "Epoch 119/300\n",
      "150/150 [==============================] - 0s 76us/sample - loss: 0.5419 - accuracy: 0.7467\n",
      "Epoch 120/300\n",
      "150/150 [==============================] - 0s 109us/sample - loss: 0.5394 - accuracy: 0.7467\n",
      "Epoch 121/300\n",
      "150/150 [==============================] - 0s 75us/sample - loss: 0.5369 - accuracy: 0.7467\n",
      "Epoch 122/300\n",
      "150/150 [==============================] - 0s 76us/sample - loss: 0.5346 - accuracy: 0.7467\n",
      "Epoch 123/300\n",
      "150/150 [==============================] - 0s 61us/sample - loss: 0.5321 - accuracy: 0.7467\n",
      "Epoch 124/300\n",
      "150/150 [==============================] - 0s 153us/sample - loss: 0.5297 - accuracy: 0.7533\n",
      "Epoch 125/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.5275 - accuracy: 0.7533\n",
      "Epoch 126/300\n",
      "150/150 [==============================] - 0s 77us/sample - loss: 0.5252 - accuracy: 0.7533\n",
      "Epoch 127/300\n",
      "150/150 [==============================] - 0s 62us/sample - loss: 0.5230 - accuracy: 0.7600\n",
      "Epoch 128/300\n",
      "150/150 [==============================] - 0s 76us/sample - loss: 0.5208 - accuracy: 0.7600\n",
      "Epoch 129/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.5187 - accuracy: 0.7600\n",
      "Epoch 130/300\n",
      "150/150 [==============================] - 0s 132us/sample - loss: 0.5165 - accuracy: 0.7667\n",
      "Epoch 131/300\n",
      "150/150 [==============================] - 0s 85us/sample - loss: 0.5145 - accuracy: 0.7667\n",
      "Epoch 132/300\n",
      "150/150 [==============================] - 0s 85us/sample - loss: 0.5124 - accuracy: 0.7667\n",
      "Epoch 133/300\n",
      "150/150 [==============================] - 0s 104us/sample - loss: 0.5104 - accuracy: 0.7667\n",
      "Epoch 134/300\n",
      "150/150 [==============================] - 0s 88us/sample - loss: 0.5085 - accuracy: 0.7733\n",
      "Epoch 135/300\n",
      "150/150 [==============================] - 0s 89us/sample - loss: 0.5066 - accuracy: 0.7733\n",
      "Epoch 136/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.5046 - accuracy: 0.7733\n",
      "Epoch 137/300\n",
      "150/150 [==============================] - 0s 57us/sample - loss: 0.5027 - accuracy: 0.7733\n",
      "Epoch 138/300\n",
      "150/150 [==============================] - 0s 70us/sample - loss: 0.5008 - accuracy: 0.7733\n",
      "Epoch 139/300\n",
      "150/150 [==============================] - 0s 77us/sample - loss: 0.4990 - accuracy: 0.7800\n",
      "Epoch 140/300\n",
      "150/150 [==============================] - 0s 55us/sample - loss: 0.4973 - accuracy: 0.7733\n",
      "Epoch 141/300\n",
      "150/150 [==============================] - 0s 69us/sample - loss: 0.4953 - accuracy: 0.7800\n",
      "Epoch 142/300\n",
      "150/150 [==============================] - 0s 69us/sample - loss: 0.4936 - accuracy: 0.7867\n",
      "Epoch 143/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.4919 - accuracy: 0.7867\n",
      "Epoch 144/300\n",
      "150/150 [==============================] - 0s 48us/sample - loss: 0.4901 - accuracy: 0.7933\n",
      "Epoch 145/300\n",
      "150/150 [==============================] - 0s 85us/sample - loss: 0.4885 - accuracy: 0.7933\n",
      "Epoch 146/300\n",
      "150/150 [==============================] - 0s 77us/sample - loss: 0.4867 - accuracy: 0.7933\n",
      "Epoch 147/300\n",
      "150/150 [==============================] - 0s 57us/sample - loss: 0.4851 - accuracy: 0.7933\n",
      "Epoch 148/300\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.4835 - accuracy: 0.7933\n",
      "Epoch 149/300\n",
      "150/150 [==============================] - 0s 102us/sample - loss: 0.4819 - accuracy: 0.7933\n",
      "Epoch 150/300\n",
      "150/150 [==============================] - 0s 89us/sample - loss: 0.4803 - accuracy: 0.7933\n",
      "Epoch 151/300\n",
      "150/150 [==============================] - 0s 72us/sample - loss: 0.4787 - accuracy: 0.7933\n",
      "Epoch 152/300\n",
      "150/150 [==============================] - 0s 66us/sample - loss: 0.4773 - accuracy: 0.7933\n",
      "Epoch 153/300\n",
      "150/150 [==============================] - 0s 84us/sample - loss: 0.4757 - accuracy: 0.7933\n",
      "Epoch 154/300\n",
      "150/150 [==============================] - 0s 69us/sample - loss: 0.4742 - accuracy: 0.8067\n",
      "Epoch 155/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 76us/sample - loss: 0.4728 - accuracy: 0.8067\n",
      "Epoch 156/300\n",
      "150/150 [==============================] - 0s 124us/sample - loss: 0.4713 - accuracy: 0.8067\n",
      "Epoch 157/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.4698 - accuracy: 0.8067\n",
      "Epoch 158/300\n",
      "150/150 [==============================] - 0s 78us/sample - loss: 0.4683 - accuracy: 0.8067\n",
      "Epoch 159/300\n",
      "150/150 [==============================] - 0s 76us/sample - loss: 0.4670 - accuracy: 0.8133\n",
      "Epoch 160/300\n",
      "150/150 [==============================] - 0s 81us/sample - loss: 0.4656 - accuracy: 0.8200\n",
      "Epoch 161/300\n",
      "150/150 [==============================] - 0s 90us/sample - loss: 0.4642 - accuracy: 0.8200\n",
      "Epoch 162/300\n",
      "150/150 [==============================] - 0s 116us/sample - loss: 0.4628 - accuracy: 0.8200\n",
      "Epoch 163/300\n",
      "150/150 [==============================] - 0s 110us/sample - loss: 0.4614 - accuracy: 0.8200\n",
      "Epoch 164/300\n",
      "150/150 [==============================] - 0s 89us/sample - loss: 0.4601 - accuracy: 0.8200\n",
      "Epoch 165/300\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.4589 - accuracy: 0.8133\n",
      "Epoch 166/300\n",
      "150/150 [==============================] - 0s 96us/sample - loss: 0.4575 - accuracy: 0.8133\n",
      "Epoch 167/300\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.4563 - accuracy: 0.8133\n",
      "Epoch 168/300\n",
      "150/150 [==============================] - 0s 76us/sample - loss: 0.4550 - accuracy: 0.8133\n",
      "Epoch 169/300\n",
      "150/150 [==============================] - 0s 103us/sample - loss: 0.4537 - accuracy: 0.8133\n",
      "Epoch 170/300\n",
      "150/150 [==============================] - 0s 132us/sample - loss: 0.4525 - accuracy: 0.8133\n",
      "Epoch 171/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4513 - accuracy: 0.8133\n",
      "Epoch 172/300\n",
      "150/150 [==============================] - 0s 78us/sample - loss: 0.4500 - accuracy: 0.8133\n",
      "Epoch 173/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.4489 - accuracy: 0.8133\n",
      "Epoch 174/300\n",
      "150/150 [==============================] - 0s 76us/sample - loss: 0.4477 - accuracy: 0.8200\n",
      "Epoch 175/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.4465 - accuracy: 0.8200\n",
      "Epoch 176/300\n",
      "150/150 [==============================] - 0s 70us/sample - loss: 0.4454 - accuracy: 0.8200\n",
      "Epoch 177/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4442 - accuracy: 0.8200\n",
      "Epoch 178/300\n",
      "150/150 [==============================] - 0s 77us/sample - loss: 0.4431 - accuracy: 0.8200\n",
      "Epoch 179/300\n",
      "150/150 [==============================] - 0s 97us/sample - loss: 0.4420 - accuracy: 0.8200\n",
      "Epoch 180/300\n",
      "150/150 [==============================] - 0s 108us/sample - loss: 0.4409 - accuracy: 0.8200\n",
      "Epoch 181/300\n",
      "150/150 [==============================] - 0s 77us/sample - loss: 0.4398 - accuracy: 0.8200\n",
      "Epoch 182/300\n",
      "150/150 [==============================] - 0s 75us/sample - loss: 0.4386 - accuracy: 0.8200\n",
      "Epoch 183/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4375 - accuracy: 0.8200\n",
      "Epoch 184/300\n",
      "150/150 [==============================] - 0s 578us/sample - loss: 0.4365 - accuracy: 0.8200\n",
      "Epoch 185/300\n",
      "150/150 [==============================] - 0s 108us/sample - loss: 0.4355 - accuracy: 0.8200\n",
      "Epoch 186/300\n",
      "150/150 [==============================] - 0s 69us/sample - loss: 0.4344 - accuracy: 0.8200\n",
      "Epoch 187/300\n",
      "150/150 [==============================] - 0s 91us/sample - loss: 0.4334 - accuracy: 0.8200\n",
      "Epoch 188/300\n",
      "150/150 [==============================] - 0s 70us/sample - loss: 0.4323 - accuracy: 0.8200\n",
      "Epoch 189/300\n",
      "150/150 [==============================] - 0s 62us/sample - loss: 0.4314 - accuracy: 0.8333\n",
      "Epoch 190/300\n",
      "150/150 [==============================] - 0s 74us/sample - loss: 0.4304 - accuracy: 0.8267\n",
      "Epoch 191/300\n",
      "150/150 [==============================] - 0s 114us/sample - loss: 0.4292 - accuracy: 0.8333\n",
      "Epoch 192/300\n",
      "150/150 [==============================] - 0s 65us/sample - loss: 0.4283 - accuracy: 0.8333\n",
      "Epoch 193/300\n",
      "150/150 [==============================] - 0s 66us/sample - loss: 0.4273 - accuracy: 0.8333\n",
      "Epoch 194/300\n",
      "150/150 [==============================] - 0s 82us/sample - loss: 0.4262 - accuracy: 0.8333\n",
      "Epoch 195/300\n",
      "150/150 [==============================] - 0s 108us/sample - loss: 0.4252 - accuracy: 0.8333\n",
      "Epoch 196/300\n",
      "150/150 [==============================] - 0s 226us/sample - loss: 0.4243 - accuracy: 0.8333\n",
      "Epoch 197/300\n",
      "150/150 [==============================] - 0s 436us/sample - loss: 0.4233 - accuracy: 0.8333\n",
      "Epoch 198/300\n",
      "150/150 [==============================] - 0s 191us/sample - loss: 0.4224 - accuracy: 0.8333\n",
      "Epoch 199/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.4215 - accuracy: 0.8333\n",
      "Epoch 200/300\n",
      "150/150 [==============================] - 0s 76us/sample - loss: 0.4205 - accuracy: 0.8333\n",
      "Epoch 201/300\n",
      "150/150 [==============================] - 0s 71us/sample - loss: 0.4196 - accuracy: 0.8333\n",
      "Epoch 202/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.4187 - accuracy: 0.8400\n",
      "Epoch 203/300\n",
      "150/150 [==============================] - 0s 79us/sample - loss: 0.4177 - accuracy: 0.8400\n",
      "Epoch 204/300\n",
      "150/150 [==============================] - 0s 131us/sample - loss: 0.4169 - accuracy: 0.8333\n",
      "Epoch 205/300\n",
      "150/150 [==============================] - 0s 84us/sample - loss: 0.4159 - accuracy: 0.8333\n",
      "Epoch 206/300\n",
      "150/150 [==============================] - 0s 75us/sample - loss: 0.4149 - accuracy: 0.8333\n",
      "Epoch 207/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.4141 - accuracy: 0.8400\n",
      "Epoch 208/300\n",
      "150/150 [==============================] - 0s 323us/sample - loss: 0.4131 - accuracy: 0.8533\n",
      "Epoch 209/300\n",
      "150/150 [==============================] - 0s 66us/sample - loss: 0.4123 - accuracy: 0.8533\n",
      "Epoch 210/300\n",
      "150/150 [==============================] - 0s 76us/sample - loss: 0.4114 - accuracy: 0.8533\n",
      "Epoch 211/300\n",
      "150/150 [==============================] - 0s 125us/sample - loss: 0.4105 - accuracy: 0.8533\n",
      "Epoch 212/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.4096 - accuracy: 0.8533\n",
      "Epoch 213/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.4087 - accuracy: 0.8533\n",
      "Epoch 214/300\n",
      "150/150 [==============================] - 0s 75us/sample - loss: 0.4082 - accuracy: 0.8533\n",
      "Epoch 215/300\n",
      "150/150 [==============================] - 0s 137us/sample - loss: 0.4070 - accuracy: 0.8533\n",
      "Epoch 216/300\n",
      "150/150 [==============================] - 0s 148us/sample - loss: 0.4062 - accuracy: 0.8533\n",
      "Epoch 217/300\n",
      "150/150 [==============================] - 0s 105us/sample - loss: 0.4053 - accuracy: 0.8533\n",
      "Epoch 218/300\n",
      "150/150 [==============================] - 0s 131us/sample - loss: 0.4045 - accuracy: 0.8533\n",
      "Epoch 219/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4036 - accuracy: 0.8533\n",
      "Epoch 220/300\n",
      "150/150 [==============================] - 0s 238us/sample - loss: 0.4029 - accuracy: 0.8533\n",
      "Epoch 221/300\n",
      "150/150 [==============================] - 0s 215us/sample - loss: 0.4021 - accuracy: 0.8533\n",
      "Epoch 222/300\n",
      "150/150 [==============================] - 0s 104us/sample - loss: 0.4013 - accuracy: 0.8533\n",
      "Epoch 223/300\n",
      "150/150 [==============================] - 0s 235us/sample - loss: 0.4003 - accuracy: 0.8533\n",
      "Epoch 224/300\n",
      "150/150 [==============================] - 0s 97us/sample - loss: 0.3996 - accuracy: 0.8533\n",
      "Epoch 225/300\n",
      "150/150 [==============================] - 0s 77us/sample - loss: 0.3988 - accuracy: 0.8600\n",
      "Epoch 226/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.3980 - accuracy: 0.8667\n",
      "Epoch 227/300\n",
      "150/150 [==============================] - 0s 105us/sample - loss: 0.3974 - accuracy: 0.8667\n",
      "Epoch 228/300\n",
      "150/150 [==============================] - 0s 68us/sample - loss: 0.3966 - accuracy: 0.8733\n",
      "Epoch 229/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.3957 - accuracy: 0.8733\n",
      "Epoch 230/300\n",
      "150/150 [==============================] - 0s 98us/sample - loss: 0.3950 - accuracy: 0.8667\n",
      "Epoch 231/300\n",
      "150/150 [==============================] - 0s 105us/sample - loss: 0.3942 - accuracy: 0.8667\n",
      "Epoch 232/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 83us/sample - loss: 0.3934 - accuracy: 0.8667\n",
      "Epoch 233/300\n",
      "150/150 [==============================] - 0s 63us/sample - loss: 0.3926 - accuracy: 0.8667\n",
      "Epoch 234/300\n",
      "150/150 [==============================] - 0s 74us/sample - loss: 0.3918 - accuracy: 0.8667\n",
      "Epoch 235/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.3911 - accuracy: 0.8667\n",
      "Epoch 236/300\n",
      "150/150 [==============================] - 0s 78us/sample - loss: 0.3903 - accuracy: 0.8667\n",
      "Epoch 237/300\n",
      "150/150 [==============================] - 0s 72us/sample - loss: 0.3896 - accuracy: 0.8667\n",
      "Epoch 238/300\n",
      "150/150 [==============================] - 0s 74us/sample - loss: 0.3889 - accuracy: 0.8667\n",
      "Epoch 239/300\n",
      "150/150 [==============================] - 0s 74us/sample - loss: 0.3881 - accuracy: 0.8667\n",
      "Epoch 240/300\n",
      "150/150 [==============================] - 0s 89us/sample - loss: 0.3874 - accuracy: 0.8667\n",
      "Epoch 241/300\n",
      "150/150 [==============================] - 0s 55us/sample - loss: 0.3866 - accuracy: 0.8733\n",
      "Epoch 242/300\n",
      "150/150 [==============================] - 0s 148us/sample - loss: 0.3859 - accuracy: 0.8800\n",
      "Epoch 243/300\n",
      "150/150 [==============================] - 0s 145us/sample - loss: 0.3853 - accuracy: 0.8800\n",
      "Epoch 244/300\n",
      "150/150 [==============================] - 0s 79us/sample - loss: 0.3845 - accuracy: 0.8800\n",
      "Epoch 245/300\n",
      "150/150 [==============================] - 0s 97us/sample - loss: 0.3837 - accuracy: 0.8800\n",
      "Epoch 246/300\n",
      "150/150 [==============================] - 0s 102us/sample - loss: 0.3830 - accuracy: 0.8800\n",
      "Epoch 247/300\n",
      "150/150 [==============================] - 0s 83us/sample - loss: 0.3824 - accuracy: 0.8800\n",
      "Epoch 248/300\n",
      "150/150 [==============================] - 0s 97us/sample - loss: 0.3816 - accuracy: 0.8800\n",
      "Epoch 249/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.3809 - accuracy: 0.8800\n",
      "Epoch 250/300\n",
      "150/150 [==============================] - 0s 101us/sample - loss: 0.3802 - accuracy: 0.8800\n",
      "Epoch 251/300\n",
      "150/150 [==============================] - 0s 90us/sample - loss: 0.3795 - accuracy: 0.8800\n",
      "Epoch 252/300\n",
      "150/150 [==============================] - 0s 157us/sample - loss: 0.3788 - accuracy: 0.8800\n",
      "Epoch 253/300\n",
      "150/150 [==============================] - 0s 132us/sample - loss: 0.3782 - accuracy: 0.8800\n",
      "Epoch 254/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3774 - accuracy: 0.8800\n",
      "Epoch 255/300\n",
      "150/150 [==============================] - 0s 130us/sample - loss: 0.3767 - accuracy: 0.8800\n",
      "Epoch 256/300\n",
      "150/150 [==============================] - 0s 196us/sample - loss: 0.3760 - accuracy: 0.8800\n",
      "Epoch 257/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.3753 - accuracy: 0.8800\n",
      "Epoch 258/300\n",
      "150/150 [==============================] - 0s 110us/sample - loss: 0.3747 - accuracy: 0.8800\n",
      "Epoch 259/300\n",
      "150/150 [==============================] - 0s 174us/sample - loss: 0.3741 - accuracy: 0.8800\n",
      "Epoch 260/300\n",
      "150/150 [==============================] - 0s 125us/sample - loss: 0.3734 - accuracy: 0.8800\n",
      "Epoch 261/300\n",
      "150/150 [==============================] - 0s 101us/sample - loss: 0.3726 - accuracy: 0.8800\n",
      "Epoch 262/300\n",
      "150/150 [==============================] - 0s 108us/sample - loss: 0.3719 - accuracy: 0.8800\n",
      "Epoch 263/300\n",
      "150/150 [==============================] - 0s 78us/sample - loss: 0.3712 - accuracy: 0.8800\n",
      "Epoch 264/300\n",
      "150/150 [==============================] - 0s 78us/sample - loss: 0.3707 - accuracy: 0.8800\n",
      "Epoch 265/300\n",
      "150/150 [==============================] - 0s 74us/sample - loss: 0.3699 - accuracy: 0.8800\n",
      "Epoch 266/300\n",
      "150/150 [==============================] - 0s 68us/sample - loss: 0.3693 - accuracy: 0.8800\n",
      "Epoch 267/300\n",
      "150/150 [==============================] - 0s 101us/sample - loss: 0.3685 - accuracy: 0.8800\n",
      "Epoch 268/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.3679 - accuracy: 0.8800\n",
      "Epoch 269/300\n",
      "150/150 [==============================] - 0s 70us/sample - loss: 0.3672 - accuracy: 0.8867\n",
      "Epoch 270/300\n",
      "150/150 [==============================] - 0s 150us/sample - loss: 0.3667 - accuracy: 0.8867\n",
      "Epoch 271/300\n",
      "150/150 [==============================] - 0s 98us/sample - loss: 0.3659 - accuracy: 0.8867\n",
      "Epoch 272/300\n",
      "150/150 [==============================] - 0s 96us/sample - loss: 0.3652 - accuracy: 0.8867\n",
      "Epoch 273/300\n",
      "150/150 [==============================] - 0s 85us/sample - loss: 0.3645 - accuracy: 0.8867\n",
      "Epoch 274/300\n",
      "150/150 [==============================] - 0s 95us/sample - loss: 0.3639 - accuracy: 0.8867\n",
      "Epoch 275/300\n",
      "150/150 [==============================] - 0s 111us/sample - loss: 0.3632 - accuracy: 0.8867\n",
      "Epoch 276/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.3626 - accuracy: 0.8867\n",
      "Epoch 277/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.3620 - accuracy: 0.8867\n",
      "Epoch 278/300\n",
      "150/150 [==============================] - 0s 115us/sample - loss: 0.3612 - accuracy: 0.8867\n",
      "Epoch 279/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.3606 - accuracy: 0.8867\n",
      "Epoch 280/300\n",
      "150/150 [==============================] - 0s 97us/sample - loss: 0.3599 - accuracy: 0.8933\n",
      "Epoch 281/300\n",
      "150/150 [==============================] - 0s 90us/sample - loss: 0.3593 - accuracy: 0.8933\n",
      "Epoch 282/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.3587 - accuracy: 0.8933\n",
      "Epoch 283/300\n",
      "150/150 [==============================] - 0s 84us/sample - loss: 0.3579 - accuracy: 0.8933\n",
      "Epoch 284/300\n",
      "150/150 [==============================] - 0s 99us/sample - loss: 0.3573 - accuracy: 0.8933\n",
      "Epoch 285/300\n",
      "150/150 [==============================] - 0s 90us/sample - loss: 0.3567 - accuracy: 0.8933\n",
      "Epoch 286/300\n",
      "150/150 [==============================] - 0s 95us/sample - loss: 0.3561 - accuracy: 0.8933\n",
      "Epoch 287/300\n",
      "150/150 [==============================] - 0s 89us/sample - loss: 0.3554 - accuracy: 0.8933\n",
      "Epoch 288/300\n",
      "150/150 [==============================] - 0s 70us/sample - loss: 0.3548 - accuracy: 0.8933\n",
      "Epoch 289/300\n",
      "150/150 [==============================] - 0s 109us/sample - loss: 0.3541 - accuracy: 0.8933\n",
      "Epoch 290/300\n",
      "150/150 [==============================] - 0s 204us/sample - loss: 0.3535 - accuracy: 0.8933\n",
      "Epoch 291/300\n",
      "150/150 [==============================] - 0s 174us/sample - loss: 0.3529 - accuracy: 0.8933\n",
      "Epoch 292/300\n",
      "150/150 [==============================] - 0s 135us/sample - loss: 0.3522 - accuracy: 0.8933\n",
      "Epoch 293/300\n",
      "150/150 [==============================] - 0s 74us/sample - loss: 0.3517 - accuracy: 0.8933\n",
      "Epoch 294/300\n",
      "150/150 [==============================] - 0s 82us/sample - loss: 0.3509 - accuracy: 0.8933\n",
      "Epoch 295/300\n",
      "150/150 [==============================] - 0s 108us/sample - loss: 0.3503 - accuracy: 0.8933\n",
      "Epoch 296/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.3496 - accuracy: 0.8933\n",
      "Epoch 297/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.3490 - accuracy: 0.8933\n",
      "Epoch 298/300\n",
      "150/150 [==============================] - 0s 137us/sample - loss: 0.3483 - accuracy: 0.8933\n",
      "Epoch 299/300\n",
      "150/150 [==============================] - 0s 105us/sample - loss: 0.3477 - accuracy: 0.8933\n",
      "Epoch 300/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.3471 - accuracy: 0.8933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13ffdd4a8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=scaled_X, y=y, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('final_iris_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iris_scaler.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler, 'iris_scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_model = load_model('final_iris_model.h5')\n",
    "flower_scaler = joblib.load('iris_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_example = {\n",
    "    \"sepal_length\": 5.1,\n",
    "    \"sepal_width\": 3.5,\n",
    "    \"petal_length\": 1.4,\n",
    "    \"petal_width\": 0.2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_predictions(model, scaler, sample_json):\n",
    "    flower = []    \n",
    "    for key, value in sample_json.items():\n",
    "        flower.append(value)    \n",
    "    flower = [flower]\n",
    "    flower = scaler.transform(flower)    \n",
    "    class_ind = model.predict_classes(flower)[0]\n",
    "    \n",
    "    classes = np.array(['setosa', 'versicolor', 'virginica'])\n",
    "    \n",
    "    return classes[class_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'setosa'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_predictions(flower_model, flower_scaler, flower_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width    species\n",
       "145           6.7          3.0           5.2          2.3  virginica\n",
       "146           6.3          2.5           5.0          1.9  virginica\n",
       "147           6.5          3.0           5.2          2.0  virginica\n",
       "148           6.2          3.4           5.4          2.3  virginica\n",
       "149           5.9          3.0           5.1          1.8  virginica"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "\n",
    "flower_model = load_model('final_iris_model.h5')\n",
    "flower_scaler = joblib.load('iris_scaler.pkl')\n",
    "\n",
    "def return_predictions(model, scaler, sample_json):\n",
    "    flower = []    \n",
    "    for key, value in sample_json.items():\n",
    "        flower.append(value)    \n",
    "    flower = [flower]\n",
    "    flower = scaler.transform(flower)    \n",
    "    class_ind = model.predict_classes(flower)[0]\n",
    "    \n",
    "    classes = np.array(['setosa', 'versicolor', 'virginica'])\n",
    "    \n",
    "    return classes[class_ind]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
